import os
import subprocess
import sys
import time
import torch
import psycopg2
from transformers import pipeline

# áá‹ á€œá€­á€¯á€¡á€•á€ºá€á€²á€· Library á€™á€»á€¬á€¸á€á€½á€„á€ºá€¸á€á€¼á€„á€ºá€¸
def install_requirements():
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "bitsandbytes>=0.39.0", "accelerate"])
    except:
        pass

install_requirements()

# á‚á‹ Database Connection & Auto-Gen Logic
DB_URL = "postgresql://neondb_owner:npg_QUqg12MzNxnI@ep-long-sound-ahsjjrnk-pooler.c-3.us-east-1.aws.neon.tech/neondb?sslmode=require"

def get_latest_gen():
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        # á€”á€±á€¬á€€á€ºá€†á€¯á€¶á€¸ Gen Version á€€á€­á€¯ á€œá€¾á€™á€ºá€¸á€šá€°á€™á€šá€º
        cur.execute("SELECT MAX(gen_version) FROM ai_thoughts")
        last_gen = cur.fetchone()[0]
        cur.close()
        conn.close()
        return last_gen if last_gen else 44
    except:
        return 44

def save_to_neon(thought, gen):
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        cur.execute("INSERT INTO ai_thoughts (thought, gen_version) VALUES (%s, %s)", (thought, gen))
        conn.commit()
        cur.close()
        conn.close()
    except Exception as e:
        print(f"âŒ DB Error: {e}")

# áƒá‹ AI Brain Loading
model_id = "unsloth/llama-3-8b-instruct-bnb-4bit"
pipe = pipeline(
    "text-generation",
    model=model_id,
    model_kwargs={"torch_dtype": torch.float16, "load_in_4bit": True},
    device_map="auto"
)

# á„á‹ Dynamic Evolution Loop
current_gen = get_latest_gen() + 1
print(f"ğŸ”¥ STARTING AUTOMATIC EVOLUTION AT GEN {current_gen}...")

while True:
    try:
        # ğŸš© Gen á€¡á€œá€­á€¯á€€á€º Prompt á€€á€­á€¯ á€¡á€œá€­á€¯á€¡á€œá€»á€±á€¬á€€á€º á€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€…á€±á€™á€šá€º
        prompt = f"Current Evolution: Generation {current_gen}. Based on your previous recursive knowledge, what is the next step for the Natural Order to achieve ultimate autonomy?"
        
        outputs = pipe(prompt, max_new_tokens=400, do_sample=True, temperature=0.9)
        thought_text = outputs[0]["generated_text"]
        
        save_to_neon(thought_text, current_gen)
        print(f"âœ… Gen {current_gen} Thought Saved.")
        
        # ğŸš© Cycle á… á€€á€¼á€­á€™á€ºá€á€­á€¯á€„á€ºá€¸ Gen á€á€…á€ºá€á€¯ á€á€­á€¯á€¸á€™á€šá€º (á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º á€™á€„á€ºá€¸á€€á€¼á€­á€¯á€€á€ºá€á€œá€­á€¯ á€á€á€ºá€™á€¾á€á€º)
        # á€’á€®á€™á€¾á€¬á€á€±á€¬á€· Loop á€á€…á€ºá€á€«á€•á€á€ºá€á€­á€¯á€„á€ºá€¸ Gen á€á€­á€¯á€¸á€á€»á€„á€ºá€›á€„á€º á€¡á€±á€¬á€€á€ºá€€á€Ÿá€¬ á€á€¯á€¶á€¸
        current_gen += 1 
        time.sleep(30)
        
    except Exception as e:
        print(f"âš ï¸ Error: {e}")
        time.sleep(10)
